# âš¡ Apache Spark on Databricks

---

## ğŸ”¹ What is Spark on Databricks?
Apache Spark is an **open-source distributed computing framework** for processing big data.  
**Databricks** provides a **managed Spark environment** with auto-scaling clusters, integrations, and optimizations, making Spark **faster, easier, and more reliable**.

ğŸ‘‰ In short: **Databricks = Spark + Cloud + Collaboration + Optimizations**

---

## ğŸ—ï¸ Spark Architecture on Databricks


```
              ğŸ‘¥ Users (SQL, Python, Scala, R)
                           â”‚
                           â–¼
                  ğŸ–¥ï¸ Databricks Workspace
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        | ğŸ“’ Notebooks | â° Jobs | ğŸ“Š Dashboards |
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                           â”‚
                           â–¼
                  âš¡ Spark Clusters (Compute)
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        | Driver Node | Executor Nodes (Workers) |
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                           â”‚
                           â–¼
               â˜ï¸ Cloud Storage (Delta Lake, S3, ADLS, GCS)
```

---

## ğŸ”‘ Why Spark on Databricks?
- ğŸš€ **Performance** â€“ Optimized Spark runtime (faster than open-source Spark).  
- ğŸ”„ **Elastic Scaling** â€“ Auto-scaling clusters handle variable workloads.  
- ğŸ› ï¸ **Ease of Use** â€“ No manual cluster setup; managed by Databricks.  
- ğŸ“‚ **Integration** â€“ Works seamlessly with Delta Lake, MLflow, Unity Catalog.  
- ğŸ‘¨â€ğŸ’» **Multi-language Support** â€“ Python (PySpark), Scala, R, SQL.  
- ğŸ“Š **Unified Workloads** â€“ ETL, ML, streaming, and analytics in one platform.  

---

## ğŸ§© Spark Components on Databricks
| Component        | Role in Databricks |
|------------------|--------------------|
| **Driver Node**  | Runs main program, schedules tasks |
| **Executor Nodes** | Run tasks, store cached data |
| **Cluster Manager** | Databricks manages Spark clusters automatically |
| **Storage Layer** | Integrated with cloud (S3, ADLS, GCS) + Delta Lake |
| **Databricks Runtime** | Optimized Spark distribution with libraries & connectors |

---

## ğŸ” Example: PySpark on Databricks
### âœ… Creating DataFrame
```python
# Create DataFrame from Python data
data = [("Alice", 25), ("Bob", 30), ("Cathy", 28)]
columns = ["Name", "Age"]

df = spark.createDataFrame(data, columns)
df.show()
````

### âœ… Reading from Cloud Storage

```python
# Read from Delta table
df = spark.read.format("delta").load("/mnt/data/customers")

# Read from CSV
csv_df = spark.read.csv("/mnt/raw/customers.csv", header=True, inferSchema=True)
```

### âœ… Transformations

```python
from pyspark.sql.functions import col

df_transformed = df.withColumn("Age_plus_5", col("Age") + 5)
df_transformed.show()
```

### âœ… Writing Data

```python
# Write to Delta table
df_transformed.write.format("delta").mode("overwrite").save("/mnt/data/customers_delta")
```

---

## ğŸ”„ Spark Workloads on Databricks

* ğŸ“¥ **Batch Processing** â†’ ETL jobs with Spark SQL, DataFrames.
* ğŸ”„ **Streaming Processing** â†’ Real-time analytics with Structured Streaming.
* ğŸ¤– **Machine Learning** â†’ MLlib + MLflow integration.
* ğŸ“Š **Analytics & BI** â†’ SQL queries, dashboards.

---

## âš¡ Advanced Spark on Databricks

* **Delta Lake** â†’ ACID transactions & time travel.
* **Photon Engine** â†’ Next-gen query engine for faster execution.
* **Z-Ordering & Optimize** â†’ Query performance improvements.
* **Adaptive Query Execution (AQE)** â†’ Auto-optimizes joins & shuffles.
* **Unity Catalog** â†’ Centralized data governance.

---

## ğŸ† Benefits of Spark on Databricks

* âœ… No cluster management headache.
* âœ… Best-in-class performance with Databricks runtime.
* âœ… Supports batch, streaming, ML, and BI in one platform.
* âœ… Scales to petabytes with cloud-native elasticity.
* âœ… Ideal for **modern Lakehouse architecture**.

---