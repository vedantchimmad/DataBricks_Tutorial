# ğŸ¤– MLflow Integration with Databricks  

---

## ğŸ”¹ Introduction  
**MLflow** is an **open-source machine learning (ML) lifecycle platform** integrated natively with Databricks.  
It helps manage the **end-to-end ML workflow**:  

- ğŸ“‚ **Experiment Tracking** â†’ Record & compare runs.  
- ğŸ“¦ **Model Registry** â†’ Centralized hub for managing models.  
- ğŸš€ **Deployment** â†’ Deploy models to production seamlessly.  
- ğŸ”„ **Reproducibility** â†’ Track code, data, and environment for reproducible results.  

ğŸ‘‰ With Databricks, MLflow is deeply integrated into **workspaces, notebooks, clusters, and Unity Catalog**.  

---

## ğŸ§© Key MLflow Components  

- ğŸ§ª **Tracking** â†’ Log metrics, parameters, artifacts, and models.  
- ğŸ·ï¸ **Model Registry** â†’ Manage versions, lifecycle stages (Staging, Production, Archived).  
- ğŸ—ï¸ **Projects** â†’ Package ML code for reproducibility.  
- â˜ï¸ **Deployment** â†’ Serve models with REST APIs, batch inference, or UDFs.  

---

## ğŸ–¼ï¸ MLflow + Databricks Architecture  

```
                 ğŸ‘©â€ğŸ’» Data Scientists / ML Engineers
                                 â”‚
                                 â–¼
                            Databricks ML
                        (Notebooks, Jobs, Clusters)
                                 â”‚
                                 â–¼
                            ğŸ¤– MLflow
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Tracking             â”‚ Model Registry       â”‚
       â”‚ (params, metrics)    â”‚ (versions, stages)   â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                       ğŸ—‚ï¸ Unity Catalog (Governed Models)
                                 â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚               â”‚               â”‚
             ğŸš€ Deployment   ğŸ”¬ Experimentation   ğŸ“Š BI/Apps
```

---

## ğŸ§‘â€ğŸ’» Example Usage  

### 1ï¸âƒ£ Tracking Experiments  
```python
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris

# Data
X, y = load_iris(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Model
model = RandomForestClassifier(n_estimators=50)

with mlflow.start_run():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    acc = accuracy_score(y_test, preds)

    # Log parameters and metrics
    mlflow.log_param("n_estimators", 50)
    mlflow.log_metric("accuracy", acc)

    # Log model
    mlflow.sklearn.log_model(model, "random_forest_model")
````

---

### 2ï¸âƒ£ Registering Model to Unity Catalog

```python
import mlflow

result = mlflow.register_model(
    "runs:/<RUN_ID>/random_forest_model",
    "main_catalog.ml_models.random_forest"
)
```

---

### 3ï¸âƒ£ Managing Model Lifecycle

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# Transition model to staging
client.transition_model_version_stage(
    name="main_catalog.ml_models.random_forest",
    version=1,
    stage="Staging"
)
```

---

### 4ï¸âƒ£ Model Deployment in Databricks

* ğŸ”„ **Batch Inference** â†’ Run models on Delta tables.
* âš¡ **Real-Time Inference** â†’ Serve models as REST APIs.
* ğŸ§® **UDF Inference** â†’ Use ML models directly in SQL queries.

Example: Predict with SQL UDF

```sql
SELECT
  customer_id,
  predict_churn(features) AS churn_prediction
FROM customer_features;
```

---

## âœ… Benefits of MLflow on Databricks

* ğŸ“Š **Centralized Experiment Tracking** â†’ No need for external tools.
* ğŸ—‚ï¸ **Governed Model Registry** (Unity Catalog integrated).
* ğŸš€ **Seamless Deployment** â†’ Batch, real-time, or SQL inference.
* ğŸ”’ **Security** â†’ Fine-grained access control for models.
* ğŸŒ **Collaboration** â†’ Teams share models easily across workspaces.
* ğŸ”„ **Reproducibility** â†’ Track code, data, and environment for reliable experiments.

---

## ğŸŒŸ Example Use Case

1. Data Scientist trains churn prediction model in Databricks Notebook.
2. MLflow logs **parameters, metrics, and model artifacts** automatically.
3. Model is **registered in Unity Catalog** with version control.
4. ML Engineer promotes model from **Staging â†’ Production**.
5. Business App calls REST API served model for **real-time predictions**.
6. Dashboards track model performance drift over time.

---